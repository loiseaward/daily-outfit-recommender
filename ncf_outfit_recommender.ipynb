{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<i>Copyright (c) Recommenders contributors.</i>\n",
                "\n",
                "<i>Licensed under the MIT License.</i>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Neural Collaborative Filtering\n",
                "\n",
                "Neural Collaborative Filtering (NCF) is a well known recommendation algorithm that generalizes the matrix factorization problem with multi-layer perceptron. \n",
                "\n",
                "This notebook provides an example of how to utilize and evaluate NCF implementation in the `recommenders`. We use a smaller dataset in this example to run NCF efficiently with GPU acceleration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "System version: 3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 18:02:02) \n",
                        "[Clang 18.1.8 ]\n",
                        "Pandas version: 2.3.3\n",
                        "Tensorflow version: 2.14.0\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/homebrew/Caskroom/miniforge/base/envs/ai_ml-ncf/lib/python3.9/site-packages/pandera/_pandas_deprecated.py:160: FutureWarning: Importing pandas-specific classes and functions from the\n",
                        "top-level pandera module will be **removed in a future version of pandera**.\n",
                        "If you're using pandera to validate pandas objects, we highly recommend updating\n",
                        "your import:\n",
                        "\n",
                        "```\n",
                        "# old import\n",
                        "import pandera as pa\n",
                        "\n",
                        "# new import\n",
                        "import pandera.pandas as pa\n",
                        "```\n",
                        "\n",
                        "If you're using pandera to validate objects from other compatible libraries\n",
                        "like pyspark or polars, see the supported libraries section of the documentation\n",
                        "for more information on how to import pandera:\n",
                        "\n",
                        "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
                        "\n",
                        "To disable this warning, set the environment variable:\n",
                        "\n",
                        "```\n",
                        "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
                        "```\n",
                        "\n",
                        "  warnings.warn(_future_warning, FutureWarning)\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "# tf.get_logger().setLevel('ERROR') # only show error messages\n",
                "\n",
                "from recommenders.utils.timer import Timer\n",
                "from recommenders.models.ncf.ncf_singlenode import NCF\n",
                "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
                "from recommenders.datasets.python_splitters import python_random_split\n",
                "from recommenders.evaluation.python_evaluation import (\n",
                "    map, ndcg_at_k, precision_at_k, recall_at_k\n",
                ")\n",
                "from recommenders.utils.notebook_utils import store_metadata\n",
                "\n",
                "from datasets import outfits\n",
                "\n",
                "print(\"System version: {}\".format(sys.version))\n",
                "print(\"Pandas version: {}\".format(pd.__version__))\n",
                "print(\"Tensorflow version: {}\".format(tf.__version__))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set the default parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# top k items to recommend\n",
                "TOP_K = 10\n",
                "\n",
                "# Change data size as appropriate\n",
                "OUTFITS_DATA_SIZE = '100'\n",
                "\n",
                "# Model parameters\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 256\n",
                "\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Download the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    UserId Weather Clothing  Rating  ClothingId\n",
                        "0        1   Humid   Blazer     2.2           0\n",
                        "1        1   Rainy   Blazer     2.8           0\n",
                        "2        1   Sunny   Hoodie     2.5           5\n",
                        "3        1   Sunny    Jeans     3.8           6\n",
                        "4        2  Cloudy   Hoodie     4.1           5\n",
                        "..     ...     ...      ...     ...         ...\n",
                        "95      19   Windy   Shorts     2.5          10\n",
                        "96      20   Humid     Polo     3.7           9\n",
                        "97      20   Snowy   Hoodie     5.0           5\n",
                        "98      20   Sunny   Chinos     3.3           2\n",
                        "99      20   Sunny  Joggers     2.4           7\n",
                        "\n",
                        "[100 rows x 5 columns]\n"
                    ]
                }
            ],
            "source": [
                "df = outfits.load_pandas_df(\n",
                "    header=[\"UserId\", \"Weather\", \"Clothing\", \"Rating\"],\n",
                "    filepath=f\"datasets/csv/example_feature1.csv\"\n",
                ")\n",
                "df['ClothingId'] = df['Clothing'].astype('category').cat.codes\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Split the data using the Spark splitter provided in utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test = python_random_split(\n",
                "    df, \n",
                "    ratio=0.75\n",
                ")\n",
                "train = train[train['Rating'] > 0]\n",
                "assert len(train) > 0, \"STOP: Training set is empty immediately after splitting.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Filter out any users or items in the test set that do not appear in the training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "test = test[test[\"UserId\"].isin(train[\"UserId\"].unique())]\n",
                "test = test[test[\"ClothingId\"].isin(train[\"ClothingId\"].unique())]\n",
                "\n",
                "train_sorted = train.sort_values(by=\"UserId\")\n",
                "test_sorted = test.sort_values(by=\"UserId\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Write datasets to csv files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_file = \"./train.csv\"\n",
                "test_file = \"./test.csv\"\n",
                "train_sorted.to_csv(train_file, index=False)\n",
                "test_sorted.to_csv(test_file, index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Generate an NCF dataset object from the data subsets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:recommenders.models.ncf.dataset:Indexing ./train.csv ...\n",
                        "INFO:recommenders.models.ncf.dataset:Indexing ./test.csv ...\n",
                        "INFO:recommenders.models.ncf.dataset:Indexing ./test_full.csv ...\n"
                    ]
                }
            ],
            "source": [
                "data = NCFDataset(\n",
                "  train_file=train_file, \n",
                "  test_file=test_file, \n",
                "  seed=SEED, \n",
                "  col_user=\"UserId\", \n",
                "  col_item=\"ClothingId\", \n",
                "  col_rating=\"Rating\")\n",
                "\n",
                "assert data.n_users > 0 and data.n_items > 0, \"STOP: The NCFDataset object loaded no users or items.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Train the NCF model on the training data, and get the top-k recommendations for our testing data\n",
                "\n",
                "NCF accepts implicit feedback and generates prospensity of items to be recommended to users in the scale of 0 to 1. A recommended item list can then be generated based on the scores. Note that this quickstart notebook is using a smaller number of epochs to reduce time for training. As a consequence, the model performance will be slighlty deteriorated. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/homebrew/Caskroom/miniforge/base/envs/ai_ml-ncf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
                        "  warnings.warn('`layer.apply` is deprecated and '\n",
                        "2025-10-12 06:37:28.212414: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n"
                    ]
                }
            ],
            "source": [
                "model = NCF (\n",
                "    n_users=data.n_users, \n",
                "    n_items=data.n_items,\n",
                "    model_type=\"NeuMF\",\n",
                "    n_factors=4,\n",
                "    layer_sizes=[16,8,4],\n",
                "    n_epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    learning_rate=1e-3,\n",
                "    verbose=10,\n",
                "    seed=SEED\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Took 0.5507 seconds for training.\n"
                    ]
                }
            ],
            "source": [
                "# Available for use with larger datasets\n",
                "with Timer() as train_time:\n",
                "    model.fit(data)\n",
                "\n",
                "print(\"Took {} seconds for training.\".format(train_time))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Took 0.0202 seconds for prediction.\n"
                    ]
                }
            ],
            "source": [
                "with Timer() as test_time:\n",
                "    users, items, preds = [], [], []\n",
                "    item = list(train.ClothingId.unique())\n",
                "    for user in train.UserId.unique():\n",
                "        user = [user] * len(item) \n",
                "        users.extend(user)\n",
                "        items.extend(item)\n",
                "        preds.extend(list(model.predict(user, item, is_list=True)))\n",
                "\n",
                "    all_predictions = pd.DataFrame(data={\"UserId\": users, \"ClothingId\":items, \"prediction\":preds})\n",
                "\n",
                "    merged = pd.merge(train, all_predictions, on=[\"UserId\", \"ClothingId\"], how=\"outer\")\n",
                "    all_predictions = merged[merged.Rating.isnull()].drop('Rating', axis=1)\n",
                "\n",
                "print(\"Took {} seconds for prediction.\".format(test_time))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Evaluate how well NCF performs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The ranking metrics are used for evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MAP:\t0.323413\n",
                        "NDCG:\t0.423614\n",
                        "Precision@K:\t0.113333\n",
                        "Recall@K:\t0.666667\n"
                    ]
                }
            ],
            "source": [
                "eval_map = map(test, all_predictions, col_prediction='prediction', k=TOP_K, col_user='UserId', col_item='ClothingId')\n",
                "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K, col_user='UserId', col_item='ClothingId', col_rating='Rating')\n",
                "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K, col_user='UserId', col_item='ClothingId')\n",
                "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K, col_user='UserId', col_item='ClothingId')\n",
                "\n",
                "print(\"MAP:\\t%f\" % eval_map,\n",
                "      \"NDCG:\\t%f\" % eval_ndcg,\n",
                "      \"Precision@K:\\t%f\" % eval_precision,\n",
                "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.32341269841269843,
                            "encoder": "json",
                            "name": "map"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "map"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.4236140510957339,
                            "encoder": "json",
                            "name": "ndcg"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "ndcg"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.11333333333333334,
                            "encoder": "json",
                            "name": "precision"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "precision"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.6666666666666666,
                            "encoder": "json",
                            "name": "recall"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "recall"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.5507390409999999,
                            "encoder": "json",
                            "name": "train_time"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "train_time"
                        }
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/notebook_utils.json+json": {
                            "data": 0.02023170799999985,
                            "encoder": "json",
                            "name": "test_time"
                        }
                    },
                    "metadata": {
                        "notebook_utils": {
                            "data": true,
                            "display": false,
                            "name": "test_time"
                        }
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Record results for tests - ignore this cell\n",
                "store_metadata(\"map\", eval_map)\n",
                "store_metadata(\"ndcg\", eval_ndcg)\n",
                "store_metadata(\"precision\", eval_precision)\n",
                "store_metadata(\"recall\", eval_recall)\n",
                "store_metadata(\"train_time\", train_time.interval)\n",
                "store_metadata(\"test_time\", test_time.interval)"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "kernelspec": {
            "display_name": "ai_ml-ncf",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.23"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
